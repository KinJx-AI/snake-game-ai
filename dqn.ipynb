{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "379f6979-749e-4da8-9487-43254b4cedad",
   "metadata": {},
   "source": [
    "# Check GPU availability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e249390",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "890e25b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.is_built_with_cuda()\n",
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fdda74f",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b4c71cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from snake_model import *\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "import random as rd\n",
    "\n",
    "from icecream import ic\n",
    "import logging"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4bc41a3-db60-4040-9606-a19341eaaa4b",
   "metadata": {},
   "source": [
    "# Constants & Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70ccf278-655d-4e25-a543-448e75bb5fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_RATE = 0.001\n",
    "GAMMA = 0.9\n",
    "EPSILON_DECAY_FACTOR = 0.999\n",
    "REPLAY_BUFFER_SIZE = 1000\n",
    "INIT_REPLAY_COUNT = REPLAY_BUFFER_SIZE // 2\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "def log(text):\n",
    "    logging.basicConfig(filename=\"log.txt\", level=logging.DEBUG)\n",
    "    logging.debug(text)\n",
    "\n",
    "def head_to_one_hot(head, gridSize):\n",
    "    one_hot = np.zeros((gridSize, gridSize))\n",
    "    one_hot[head.x][head.y] = 1\n",
    "    return one_hot\n",
    "\n",
    "def body_to_one_hot(bodyBlocks, gridSize):\n",
    "    one_hot = np.zeros((gridSize, gridSize))\n",
    "    for bodyBlock in bodyBlocks:\n",
    "        one_hot[bodyBlock.x][bodyBlock.y] = 1\n",
    "    return one_hot\n",
    "\n",
    "def food_to_one_hot(foods, gridSize):\n",
    "    one_hot = np.zeros((gridSize, gridSize))\n",
    "    for food in foods:\n",
    "        one_hot[food.x][food.y] = 1\n",
    "    return one_hot\n",
    "\n",
    "def action_to_direction(currentDirection, chosenAction): # 0up 1down 2left 3right : 0left 1stay 2right\n",
    "    if currentDirection == 0:\n",
    "        if chosenAction == 0:\n",
    "            return 2\n",
    "        if chosenAction == 2:\n",
    "            return 3\n",
    "    if currentDirection == 1:\n",
    "        if chosenAction == 0:\n",
    "            return 3\n",
    "        if chosenAction == 2:\n",
    "            return 2\n",
    "    if currentDirection == 2:\n",
    "        if chosenAction == 0:\n",
    "            return 1\n",
    "        if chosenAction == 2:\n",
    "            return 0\n",
    "    if currentDirection == 3:\n",
    "        if chosenAction == 0:\n",
    "            return 0\n",
    "        if chosenAction == 2:\n",
    "            return 1\n",
    "    return currentDirection\n",
    "\n",
    "def get_projected_coodinates(x, y, direction):\n",
    "    if currentDirection == 0:\n",
    "        return (x-1, y)\n",
    "    if currentDirection == 1:\n",
    "        return (x+1, y)\n",
    "    if currentDirection == 2:\n",
    "        return (x, y-1)\n",
    "    if currentDirection == 3:\n",
    "        return (x, y+1)\n",
    "\n",
    "def get_mini_batch(replay):\n",
    "    mini_batch = rd.sample(replay, BATCH_SIZE) \n",
    "    col_indices = [0,1,2,3]\n",
    "    result = [list(column) for column in zip(*mini_batch)][col_indices[0]:col_indices[-1]+1]\n",
    "    return result[0], result[1], result[2], result[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c83fd61",
   "metadata": {},
   "source": [
    "# Q Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "98745dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQN(tf.keras.Model):\n",
    "    def __init__(self, state_size, action_size):\n",
    "        super(DQN, self).__init__()\n",
    "        \n",
    "        l1 = state_size\n",
    "        l2 = 128\n",
    "        l3 = 64\n",
    "        l4 = action_size\n",
    "        \n",
    "        self.model = tf.keras.Sequential([\n",
    "            layers.Dense(l2, activation='relu', input_shape=(l1,)),\n",
    "            layers.Dense(l3, activation='relu'),\n",
    "            layers.Dense(l4)\n",
    "        ])\n",
    "\n",
    "        self.model2 = tf.keras.models.clone_model(self.model)\n",
    "        self.model2.set_weights(self.model.get_weights())\n",
    "        \n",
    "        self.loss_fn = tf.keras.losses.MeanSquaredError()\n",
    "        self.learning_rate = 0.001\n",
    "        self.optimizer = tf.keras.optimizers.Adam(learning_rate=self.learning_rate)\n",
    "\n",
    "    def update_target(self):\n",
    "        self.model2.set_weights(self.model.get_weights())\n",
    "\n",
    "    def get_qvals(self, state):\n",
    "        state = tf.convert_to_tensor(state, dtype=tf.float32)\n",
    "        q_values = self.model(state)\n",
    "        return q_values.numpy()\n",
    "\n",
    "    def get_maxQ(self, state):\n",
    "        state = tf.convert_to_tensor(state, dtype=tf.float32)\n",
    "        q_values = self.model2(state)\n",
    "        return tf.reduce_max(q_values, axis=1).numpy()\n",
    "\n",
    "    def train_one_step(self, states, actions, targets):\n",
    "        targets_reply = []\n",
    "        state1_batch = tf.convert_to_tensor(states, dtype=tf.float32)\n",
    "        action_batch = tf.convert_to_tensor(actions, dtype=tf.int32)\n",
    "        with tf.GradientTape() as tape:\n",
    "            Q1 = self.model(state1_batch)\n",
    "            X = tf.gather(Q1, action_batch, axis=1, batch_dims=1)\n",
    "            Y = tf.convert_to_tensor(targets, dtype=tf.float32)\n",
    "            loss = self.loss_fn(X, Y)\n",
    "        gradients = tape.gradient(loss, self.model.trainable_variables)\n",
    "        self.optimizer.apply_gradients(zip(gradients, self.model.trainable_variables))\n",
    "        return loss.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be56ae6e-2861-4f60-94b7-8017ebe27331",
   "metadata": {},
   "source": [
    "# Deep Q Learning Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c478a5a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Environment:\n",
    "    def __init__(self):\n",
    "        self.world = World()\n",
    "        self.state = self.get_state()\n",
    "        self.prevState = None\n",
    "        self.score = self.world.score\n",
    "        self.prevScore = self.score\n",
    "\n",
    "    def get_state(self):\n",
    "        headArray = head_to_one_hot(self.world.snake.head, self.world.size).flatten()\n",
    "        bodyArray = body_to_one_hot(self.world.snake.body, self.world.size).flatten()\n",
    "        foodArray = food_to_one_hot(self.world.foods, self.world.size).flatten()\n",
    "        state = np.array([headArray, bodyArray, foodArray]).flatten()\n",
    "        state = np.append(state, self.world.snake.direction)\n",
    "        return state\n",
    "\n",
    "    def step(self):\n",
    "        print(self.world.snake.head.x, self.world.snake.head.y)\n",
    "        self.prevState = self.get_state()\n",
    "        self.prevScore = self.world.score\n",
    "        self.world.step()\n",
    "        if not self.world.isCollide:\n",
    "            self.state = self.get_state()\n",
    "            self.score = self.world.score\n",
    "\n",
    "class Agent:\n",
    "    def __init__(self):\n",
    "        self.environment = Environment()\n",
    "        self.network = DQN((self.environment.world.size**2) * 3 + 1, 3)\n",
    "        self.replay = []\n",
    "        self.epsilon = 1\n",
    "\n",
    "        self.cumulativeScore = 0\n",
    "\n",
    "    def append_replay_table(self, action):\n",
    "        prevState = self.environment.prevState\n",
    "        reward = self.get_reward()\n",
    "        newState = self.environment.state\n",
    "        self.replay.append([prevState, action, reward, newState])\n",
    "        if len(self.replay) > REPLAY_BUFFER_SIZE:\n",
    "            self.replay.pop()\n",
    "\n",
    "    def get_reward(self):\n",
    "        reward = -1\n",
    "        if self.environment.score > self.environment.prevScore:\n",
    "            reward = 5\n",
    "            self.cumulativeScore += 1\n",
    "        if self.environment.world.isCollide:\n",
    "            reward = -5\n",
    "        return reward\n",
    "\n",
    "    def e_greedy(self, epsilon):\n",
    "        if np.random.rand() <= epsilon:\n",
    "            chosenAction = np.random.choice([0,1,2])\n",
    "            return chosenAction\n",
    "        else:\n",
    "            currentState = self.environment.get_state()\n",
    "            currentQVals = self.network.get_qvals([currentState])\n",
    "            return np.argmax(currentQVals)\n",
    "\n",
    "    def step(self):\n",
    "        chosenAction = self.e_greedy(self.epsilon)\n",
    "        newDirection = action_to_direction(self.environment.world.snake.direction, chosenAction)\n",
    "        self.environment.world.snake.change_direction(newDirection)\n",
    "        self.environment.step()\n",
    "        self.append_replay_table(chosenAction)\n",
    "        \n",
    "\n",
    "class DeepQLearning:\n",
    "    def __init__(self):\n",
    "        self.time = 0\n",
    "        self.agent = Agent()\n",
    "\n",
    "        self.init_replay_table()\n",
    "    \n",
    "    def init_replay_table(self):\n",
    "        for i in range (INIT_REPLAY_COUNT):\n",
    "            self.agent.step()\n",
    "            if self.agent.environment.world.isCollide:\n",
    "                self.agent.environment.world.__init__()\n",
    "\n",
    "        self.agent.epsilon = 1        \n",
    "\n",
    "    def train_network(self):\n",
    "        prevStates, actions, rewards, newStates = get_mini_batch(self.agent.replay)\n",
    "        maxQValues = self.agent.network.get_maxQ(newStates)\n",
    "        targets = []\n",
    "        for i in range (len(rewards)):\n",
    "            targets.append(rewards[i] + (GAMMA * maxQValues[i]))\n",
    "\n",
    "        self.agent.network.train_one_step(prevStates, actions, targets)\n",
    "        \n",
    "    def step(self):\n",
    "        self.agent.step()\n",
    "\n",
    "        if self.time % 10 == 0:\n",
    "            self.train_network()\n",
    "            self.agent.epsilon *= EPSILON_DECAY_FACTOR\n",
    "\n",
    "        if self.time % 1000 == 0:\n",
    "            self.agent.network.update_target()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "280e8deb-815a-4e42-b398-1e357d82a36a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 5\n",
      "4 5\n",
      "4 6\n",
      "5 6\n",
      "6 6\n",
      "7 6\n",
      "8 6\n",
      "8 7\n",
      "7 7\n",
      "7 6\n",
      "6 6\n",
      "6 5\n",
      "7 5\n",
      "8 5\n",
      "8 4\n",
      "7 4\n",
      "6 4\n",
      "5 4\n",
      "5 5\n",
      "4 5\n",
      "3 5\n",
      "2 5\n",
      "1 5\n",
      "0 5\n",
      "0 4\n",
      "1 4\n",
      "1 3\n",
      "2 3\n",
      "2 2\n",
      "3 2\n",
      "4 2\n",
      "4 3\n",
      "4 4\n",
      "3 4\n",
      "2 4\n",
      "2 3\n",
      "2 2\n",
      "3 2\n",
      "3 3\n",
      "2 3\n",
      "2 2\n",
      "3 2\n",
      "3 1\n",
      "3 0\n",
      "2 0\n",
      "1 0\n",
      "0 0\n",
      "5 5\n",
      "4 5\n",
      "4 6\n",
      "5 6\n",
      "5 7\n",
      "6 7\n",
      "7 7\n",
      "7 8\n",
      "6 8\n",
      "6 7\n",
      "5 7\n",
      "5 8\n",
      "4 8\n",
      "4 7\n",
      "3 7\n",
      "3 8\n",
      "2 8\n",
      "1 8\n",
      "1 9\n",
      "0 9\n",
      "5 5\n",
      "4 5\n",
      "4 6\n",
      "3 6\n",
      "3 5\n",
      "2 5\n",
      "1 5\n",
      "1 6\n",
      "1 7\n",
      "2 7\n",
      "3 7\n",
      "3 6\n",
      "4 6\n",
      "4 7\n",
      "3 7\n",
      "3 8\n",
      "2 8\n",
      "2 9\n",
      "3 9\n",
      "3 8\n",
      "2 8\n",
      "2 7\n",
      "1 7\n",
      "1 6\n",
      "0 6\n",
      "0 7\n",
      "1 7\n",
      "1 6\n",
      "1 5\n",
      "1 4\n",
      "2 4\n",
      "2 3\n",
      "2 2\n",
      "3 2\n",
      "3 3\n",
      "2 3\n",
      "1 3\n",
      "0 3\n",
      "0 4\n",
      "1 4\n",
      "1 5\n",
      "2 5\n",
      "2 4\n",
      "2 3\n",
      "2 2\n",
      "1 2\n",
      "1 3\n",
      "2 3\n",
      "3 3\n",
      "3 4\n",
      "2 4\n",
      "2 3\n",
      "2 2\n",
      "3 2\n",
      "3 3\n",
      "4 3\n",
      "5 3\n",
      "6 3\n",
      "6 2\n",
      "7 2\n",
      "7 1\n",
      "8 1\n",
      "8 2\n",
      "9 2\n",
      "9 3\n",
      "9 4\n",
      "8 4\n",
      "8 3\n",
      "9 3\n",
      "9 2\n",
      "8 2\n",
      "8 3\n",
      "9 3\n",
      "9 4\n",
      "5 5\n",
      "4 5\n",
      "3 5\n",
      "2 5\n",
      "2 4\n",
      "1 4\n",
      "1 3\n",
      "0 3\n",
      "5 5\n",
      "5 4\n",
      "4 4\n",
      "4 3\n",
      "3 3\n",
      "3 2\n",
      "3 1\n",
      "3 0\n",
      "4 0\n",
      "5 0\n",
      "5 5\n",
      "4 5\n",
      "3 5\n",
      "3 6\n",
      "3 7\n",
      "3 8\n",
      "4 8\n",
      "5 8\n",
      "5 7\n",
      "5 6\n",
      "5 5\n",
      "6 5\n",
      "6 6\n",
      "6 7\n",
      "6 8\n",
      "7 8\n",
      "8 8\n",
      "9 8\n",
      "9 9\n",
      "5 5\n",
      "5 6\n",
      "5 7\n",
      "5 8\n",
      "4 8\n",
      "4 9\n",
      "5 9\n",
      "5 5\n",
      "5 4\n",
      "6 4\n",
      "6 5\n",
      "6 6\n",
      "5 6\n",
      "5 5\n",
      "5 4\n",
      "4 4\n",
      "4 3\n",
      "4 2\n",
      "5 2\n",
      "5 1\n",
      "6 1\n",
      "7 1\n",
      "8 1\n",
      "9 1\n",
      "5 5\n",
      "5 4\n",
      "4 4\n",
      "4 5\n",
      "4 6\n",
      "4 7\n",
      "4 8\n",
      "3 8\n",
      "3 7\n",
      "4 7\n",
      "4 8\n",
      "5 8\n",
      "5 7\n",
      "6 7\n",
      "6 8\n",
      "6 9\n",
      "5 5\n",
      "5 4\n",
      "6 4\n",
      "6 3\n",
      "6 2\n",
      "7 2\n",
      "8 2\n",
      "8 3\n",
      "8 4\n",
      "7 4\n",
      "7 5\n",
      "8 5\n",
      "8 6\n",
      "7 6\n",
      "7 7\n",
      "7 8\n",
      "6 8\n",
      "6 7\n",
      "6 6\n",
      "6 5\n",
      "6 4\n",
      "5 4\n",
      "5 5\n",
      "6 5\n",
      "6 4\n",
      "5 4\n",
      "4 4\n",
      "3 4\n",
      "3 3\n",
      "3 2\n",
      "2 2\n",
      "2 1\n",
      "3 1\n",
      "3 2\n",
      "2 2\n",
      "2 1\n",
      "3 1\n",
      "3 0\n",
      "5 5\n",
      "5 6\n",
      "5 7\n",
      "4 7\n",
      "3 7\n",
      "2 7\n",
      "1 7\n",
      "1 8\n",
      "1 9\n",
      "2 9\n",
      "3 9\n",
      "3 8\n",
      "2 8\n",
      "1 8\n",
      "0 8\n",
      "0 9\n",
      "5 5\n",
      "4 5\n",
      "3 5\n",
      "3 6\n",
      "3 7\n",
      "3 8\n",
      "3 9\n",
      "5 5\n",
      "5 4\n",
      "5 3\n",
      "5 2\n",
      "5 1\n",
      "5 0\n",
      "6 0\n",
      "6 1\n",
      "7 1\n",
      "7 0\n",
      "6 0\n",
      "6 1\n",
      "5 1\n",
      "5 0\n",
      "6 0\n",
      "5 5\n",
      "5 4\n",
      "4 4\n",
      "4 3\n",
      "4 2\n",
      "4 1\n",
      "3 1\n",
      "3 2\n",
      "4 2\n",
      "5 2\n",
      "5 1\n",
      "6 1\n",
      "7 1\n",
      "8 1\n",
      "8 0\n",
      "7 0\n",
      "5 5\n",
      "5 6\n",
      "6 6\n",
      "6 7\n",
      "7 7\n",
      "7 6\n",
      "8 6\n",
      "8 7\n",
      "7 7\n",
      "7 6\n",
      "8 6\n",
      "8 5\n",
      "9 5\n",
      "9 4\n",
      "9 3\n",
      "5 5\n",
      "4 5\n",
      "4 4\n",
      "3 4\n",
      "2 4\n",
      "1 4\n",
      "0 4\n",
      "5 5\n",
      "5 6\n",
      "6 6\n",
      "6 5\n",
      "7 5\n",
      "8 5\n",
      "8 6\n",
      "7 6\n",
      "7 5\n",
      "6 5\n",
      "6 6\n",
      "7 6\n",
      "7 5\n",
      "7 4\n",
      "6 4\n",
      "6 3\n",
      "5 3\n",
      "5 4\n",
      "4 4\n",
      "4 3\n",
      "4 2\n",
      "3 2\n",
      "3 3\n",
      "2 3\n",
      "2 2\n",
      "3 2\n",
      "3 3\n",
      "2 3\n",
      "1 3\n",
      "1 2\n",
      "0 2\n",
      "5 5\n",
      "5 6\n",
      "5 7\n",
      "5 8\n",
      "6 8\n",
      "6 7\n",
      "6 6\n",
      "7 6\n",
      "8 6\n",
      "8 5\n",
      "8 4\n",
      "9 4\n",
      "5 5\n",
      "5 6\n",
      "6 6\n",
      "7 6\n",
      "8 6\n",
      "9 6\n",
      "9 7\n",
      "8 7\n",
      "8 6\n",
      "8 5\n",
      "7 5\n",
      "7 4\n",
      "8 4\n",
      "9 4\n",
      "9 3\n",
      "5 5\n",
      "5 6\n",
      "5 7\n",
      "4 7\n",
      "3 7\n",
      "3 8\n",
      "4 8\n",
      "4 7\n",
      "3 7\n",
      "3 8\n",
      "2 8\n",
      "1 8\n",
      "1 9\n",
      "5 5\n",
      "5 4\n",
      "6 4\n",
      "7 4\n",
      "8 4\n",
      "8 3\n",
      "7 3\n",
      "7 2\n",
      "8 2\n",
      "8 1\n",
      "8 0\n",
      "7 0\n",
      "6 0\n",
      "5 5\n",
      "4 5\n",
      "3 5\n",
      "3 6\n",
      "4 6\n",
      "4 7\n",
      "4 8\n",
      "4 9\n",
      "5 5\n",
      "5 6\n",
      "6 6\n",
      "6 7\n",
      "5 7\n",
      "5 6\n",
      "4 6\n",
      "4 7\n",
      "4 8\n",
      "3 8\n",
      "3 7\n",
      "2 7\n",
      "2 6\n",
      "2 5\n",
      "3 5\n",
      "3 4\n",
      "2 4\n",
      "2 3\n",
      "3 3\n",
      "3 4\n",
      "4 4\n",
      "4 3\n",
      "5 3\n",
      "5 4\n",
      "6 4\n",
      "6 5\n",
      "6 6\n",
      "5 6\n",
      "4 6\n",
      "4 5\n",
      "3 5\n",
      "3 4\n",
      "4 4\n",
      "4 5\n",
      "4 6\n",
      "4 7\n",
      "4 8\n",
      "4 9\n",
      "3 9\n",
      "5 5\n",
      "5 4\n",
      "4 4\n",
      "4 5\n",
      "4 6\n",
      "4 7\n",
      "4 8\n",
      "3 8\n",
      "2 8\n",
      "2 9\n",
      "5 5\n",
      "5 6\n",
      "6 6\n",
      "6 5\n",
      "5 5\n",
      "4 5\n",
      "4 4\n",
      "5 4\n",
      "5 5\n",
      "5 6\n",
      "4 6\n",
      "4 7\n",
      "4 8\n",
      "4 9\n",
      "5 5\n",
      "5 4\n",
      "4 4\n",
      "3 4\n",
      "2 4\n",
      "2 5\n",
      "3 5\n",
      "3 4\n",
      "2 4\n",
      "2 5\n",
      "3 5\n",
      "4 5\n",
      "5 5\n",
      "5 4\n",
      "5 3e :0 | Cumulative Score : 9 | Current Score : 0\n",
      "4 3e :0 | Cumulative Score : 9 | Current Score : 0\n",
      "4 4e :0 | Cumulative Score : 9 | Current Score : 0\n",
      "5 4e :0 | Cumulative Score : 9 | Current Score : 0\n",
      "6 4e :0 | Cumulative Score : 9 | Current Score : 0\n",
      "7 4e :0 | Cumulative Score : 9 | Current Score : 0\n",
      "7 3e :0 | Cumulative Score : 9 | Current Score : 0\n",
      "6 3e :0 | Cumulative Score : 9 | Current Score : 0\n",
      "5 3e :0 | Cumulative Score : 9 | Current Score : 0\n",
      "5 2e :0 | Cumulative Score : 9 | Current Score : 0\n",
      "4 2e :0 | Cumulative Score : 9 | Current Score : 0\n",
      "4 3e :0 | Cumulative Score : 9 | Current Score : 0\n",
      "5 3e :0 | Cumulative Score : 9 | Current Score : 0\n",
      "6 3e :0 | Cumulative Score : 9 | Current Score : 0\n",
      "7 3e :0 | Cumulative Score : 9 | Current Score : 0\n",
      "8 3e :0 | Cumulative Score : 9 | Current Score : 0\n",
      "9 3e :0 | Cumulative Score : 9 | Current Score : 0\n",
      "9 4e :0 | Cumulative Score : 9 | Current Score : 0\n",
      "9 5e :0 | Cumulative Score : 9 | Current Score : 0\n",
      "9 6e :0 | Cumulative Score : 9 | Current Score : 0\n",
      "8 6e :0 | Cumulative Score : 9 | Current Score : 0\n",
      "7 6e :0 | Cumulative Score : 9 | Current Score : 0\n",
      "7 7e :0 | Cumulative Score : 9 | Current Score : 0\n",
      "8 7e :0 | Cumulative Score : 9 | Current Score : 0\n",
      "9 7e :0 | Cumulative Score : 9 | Current Score : 0\n",
      "9 8e :0 | Cumulative Score : 9 | Current Score : 0\n",
      "10 8 :0 | Cumulative Score : 9 | Current Score : 0\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 10 is out of bounds for axis 0 with size 10",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m epsilon \u001b[38;5;241m=\u001b[39m test\u001b[38;5;241m.\u001b[39magent\u001b[38;5;241m.\u001b[39mepsilon\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m epsilon \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.1\u001b[39m:\n\u001b[1;32m----> 6\u001b[0m     \u001b[43mtest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTime :\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest\u001b[38;5;241m.\u001b[39mtime\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m | Cumulative Score : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest\u001b[38;5;241m.\u001b[39magent\u001b[38;5;241m.\u001b[39mcumulativeScore\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m | Current Score : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest\u001b[38;5;241m.\u001b[39magent\u001b[38;5;241m.\u001b[39menvironment\u001b[38;5;241m.\u001b[39mworld\u001b[38;5;241m.\u001b[39mscore\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, end\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\r\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[1;32mIn[8], line 94\u001b[0m, in \u001b[0;36mDeepQLearning.step\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstep\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m---> 94\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     96\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtime \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m10\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m     97\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_network()\n",
      "Cell \u001b[1;32mIn[8], line 65\u001b[0m, in \u001b[0;36mAgent.step\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     63\u001b[0m newDirection \u001b[38;5;241m=\u001b[39m action_to_direction(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menvironment\u001b[38;5;241m.\u001b[39mworld\u001b[38;5;241m.\u001b[39msnake\u001b[38;5;241m.\u001b[39mdirection, chosenAction)\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menvironment\u001b[38;5;241m.\u001b[39mworld\u001b[38;5;241m.\u001b[39msnake\u001b[38;5;241m.\u001b[39mchange_direction(newDirection)\n\u001b[1;32m---> 65\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menvironment\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mappend_replay_table(chosenAction)\n",
      "Cell \u001b[1;32mIn[8], line 19\u001b[0m, in \u001b[0;36mEnvironment.step\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstep\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m     18\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mworld\u001b[38;5;241m.\u001b[39msnake\u001b[38;5;241m.\u001b[39mhead\u001b[38;5;241m.\u001b[39mx, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mworld\u001b[38;5;241m.\u001b[39msnake\u001b[38;5;241m.\u001b[39mhead\u001b[38;5;241m.\u001b[39my)\n\u001b[1;32m---> 19\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprevState \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_state\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     20\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprevScore \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mworld\u001b[38;5;241m.\u001b[39mscore\n\u001b[0;32m     21\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mworld\u001b[38;5;241m.\u001b[39mstep()\n",
      "Cell \u001b[1;32mIn[8], line 10\u001b[0m, in \u001b[0;36mEnvironment.get_state\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_state\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m---> 10\u001b[0m     headArray \u001b[38;5;241m=\u001b[39m \u001b[43mhead_to_one_hot\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mworld\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msnake\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhead\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mworld\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mflatten()\n\u001b[0;32m     11\u001b[0m     bodyArray \u001b[38;5;241m=\u001b[39m body_to_one_hot(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mworld\u001b[38;5;241m.\u001b[39msnake\u001b[38;5;241m.\u001b[39mbody, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mworld\u001b[38;5;241m.\u001b[39msize)\u001b[38;5;241m.\u001b[39mflatten()\n\u001b[0;32m     12\u001b[0m     foodArray \u001b[38;5;241m=\u001b[39m food_to_one_hot(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mworld\u001b[38;5;241m.\u001b[39mfoods, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mworld\u001b[38;5;241m.\u001b[39msize)\u001b[38;5;241m.\u001b[39mflatten()\n",
      "Cell \u001b[1;32mIn[4], line 14\u001b[0m, in \u001b[0;36mhead_to_one_hot\u001b[1;34m(head, gridSize)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mhead_to_one_hot\u001b[39m(head, gridSize):\n\u001b[0;32m     13\u001b[0m     one_hot \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((gridSize, gridSize))\n\u001b[1;32m---> 14\u001b[0m     \u001b[43mone_hot\u001b[49m\u001b[43m[\u001b[49m\u001b[43mhead\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m]\u001b[49m[head\u001b[38;5;241m.\u001b[39my] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m one_hot\n",
      "\u001b[1;31mIndexError\u001b[0m: index 10 is out of bounds for axis 0 with size 10"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "test = DeepQLearning()\n",
    "\n",
    "epsilon = test.agent.epsilon\n",
    "while epsilon >= 0.1:\n",
    "    test.step()\n",
    "    print(f\"Time :{test.time} | Cumulative Score : {test.agent.cumulativeScore} | Current Score : {test.agent.environment.world.score}\", end='\\r')\n",
    "# for i in range(1000):\n",
    "#     test.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd4f9b43-2262-4b02-ac88-35c86f746038",
   "metadata": {},
   "source": [
    "# Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac00776-530e-449b-8aef-00ac2ddd39f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pygame\n",
    "from sys import exit\n",
    "from snake_view import *\n",
    "\n",
    "TICK_RATE = 500\n",
    "\n",
    "pygame.init()\n",
    "pygame.display.set_caption(\"Snake\")\n",
    "\n",
    "class Game:\n",
    "    def __init__(self):\n",
    "        self.clock = pygame.time.Clock()\n",
    "        self.dqnDriver = DeepQLearning()\n",
    "        self.agent = self.dqnDriver.agent\n",
    "        self.gameWorld = self.agent.environment.world\n",
    "        self.UI = UI(self.gameWorld)\n",
    "\n",
    "    def game_loop(self):\n",
    "        while True:\n",
    "            self.handle_player_input()\n",
    "            self.agent.step()\n",
    "\n",
    "            if self.gameWorld.isCollide:\n",
    "                self.gameWorld.__init__()\n",
    "                \n",
    "            self.UI.draw_hud()\n",
    "            self.UI.draw_blocks()\n",
    "            pygame.display.update()\n",
    "            self.clock.tick(TICK_RATE)\n",
    "\n",
    "    def handle_player_input(self):\n",
    "        for event in pygame.event.get():\n",
    "            if event.type == pygame.QUIT:\n",
    "                pygame.quit()\n",
    "                exit()\n",
    "\n",
    "            if event.type == pygame.KEYDOWN:\n",
    "                if event.key == pygame.K_RETURN or event.key == pygame.K_SPACE:\n",
    "                    self.gameWorld.__init__()\n",
    "\n",
    "                elif event.key == pygame.K_ESCAPE:\n",
    "                    pygame.quit()\n",
    "                    exit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d8b787-b46b-49d1-9558-ced4a4c0662b",
   "metadata": {},
   "outputs": [],
   "source": [
    "myGame = Game()\n",
    "myGame.game_loop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eccd46b3-1952-452e-b203-6eee9cd34ec8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ded9f12-84a1-4b74-9668-1451d94dd283",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
