{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "379f6979-749e-4da8-9487-43254b4cedad",
   "metadata": {},
   "source": [
    "# Check GPU availability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e249390",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "890e25b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.is_built_with_cuda()\n",
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fdda74f",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b4c71cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from snake_model import *\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "import random as rd\n",
    "\n",
    "from icecream import ic\n",
    "import logging"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4bc41a3-db60-4040-9606-a19341eaaa4b",
   "metadata": {},
   "source": [
    "# Constants & Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70ccf278-655d-4e25-a543-448e75bb5fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_RATE = 0.001\n",
    "GAMMA = 0.9\n",
    "EPSILON_DECAY_FACTOR = 0.999\n",
    "REPLAY_BUFFER_SIZE = 1000\n",
    "INIT_REPLAY_COUNT = REPLAY_BUFFER_SIZE // 2\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "def log(text):\n",
    "    logging.basicConfig(filename=\"log.txt\", level=logging.DEBUG)\n",
    "    logging.debug(text)\n",
    "\n",
    "def head_to_one_hot(head, gridSize):\n",
    "    one_hot = np.zeros((gridSize, gridSize))\n",
    "    one_hot[head.x][head.y] = 1\n",
    "    return one_hot\n",
    "\n",
    "def body_to_one_hot(bodyBlocks, gridSize):\n",
    "    one_hot = np.zeros((gridSize, gridSize))\n",
    "    for bodyBlock in bodyBlocks:\n",
    "        one_hot[bodyBlock.x][bodyBlock.y] = 1\n",
    "    return one_hot\n",
    "\n",
    "def food_to_one_hot(foods, gridSize):\n",
    "    one_hot = np.zeros((gridSize, gridSize))\n",
    "    for food in foods:\n",
    "        one_hot[food.x][food.y] = 1\n",
    "    return one_hot\n",
    "\n",
    "def direction_to_one_hot(direction):\n",
    "    one_hot = np.zeros(4)\n",
    "    one_hot[direction] = 1\n",
    "    return one_hot\n",
    "\n",
    "def action_to_direction(currentDirection, chosenAction): # 0up 1down 2left 3right : 0left 1stay 2right\n",
    "    if currentDirection == 0:\n",
    "        if chosenAction == 0:\n",
    "            return 2\n",
    "        if chosenAction == 2:\n",
    "            return 3\n",
    "    if currentDirection == 1:\n",
    "        if chosenAction == 0:\n",
    "            return 3\n",
    "        if chosenAction == 2:\n",
    "            return 2\n",
    "    if currentDirection == 2:\n",
    "        if chosenAction == 0:\n",
    "            return 1\n",
    "        if chosenAction == 2:\n",
    "            return 0\n",
    "    if currentDirection == 3:\n",
    "        if chosenAction == 0:\n",
    "            return 0\n",
    "        if chosenAction == 2:\n",
    "            return 1\n",
    "    return currentDirection\n",
    "\n",
    "def get_mini_batch(replay):\n",
    "    mini_batch = rd.sample(replay, BATCH_SIZE) \n",
    "    col_indices = [0,1,2,3]\n",
    "    result = [list(column) for column in zip(*mini_batch)][col_indices[0]:col_indices[-1]+1]\n",
    "    return np.array(result[0]), np.array(result[1]), np.array(result[2]), np.array(result[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c83fd61",
   "metadata": {},
   "source": [
    "# Q Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "98745dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQN():\n",
    "    def __init__(self, state_size, action_size):\n",
    "        self.q_net = self.build_dqn_model(state_size, action_size)\n",
    "        self.target_q_net = self.build_dqn_model(state_size, action_size)\n",
    "\n",
    "    def build_dqn_model(self, state_size, action_size):\n",
    "\n",
    "        l1 = state_size\n",
    "        l2 = 128\n",
    "        l3 = 64\n",
    "        l4 = action_size\n",
    "        \n",
    "        q_net = tf.keras.Sequential()\n",
    "        q_net.add(layers.Dense(l2, input_dim=l1, activation='relu', kernel_initializer='he_uniform'))\n",
    "        q_net.add(layers.Dense(l3, activation='relu', kernel_initializer='he_uniform'))\n",
    "        q_net.add(layers.Dense(l4, activation='linear', kernel_initializer='he_uniform'))\n",
    "        q_net.compile(optimizer=tf.optimizers.Adam(learning_rate=0.001), loss='mse')\n",
    "        return q_net\n",
    "\n",
    "    def update_target(self):\n",
    "        self.target_q_net.set_weights(self.q_net.get_weights())\n",
    "\n",
    "    def get_qvals(self, state):\n",
    "        state = tf.convert_to_tensor(state, dtype=tf.float32)\n",
    "        q_values = self.q_net(state)\n",
    "        return q_values.numpy()\n",
    "\n",
    "    def train(self, batch):\n",
    "        state_batch, action_batch, reward_batch, next_state_batch = batch\n",
    "        current_q = self.q_net(state_batch).numpy()\n",
    "        target_q = np.copy(current_q)\n",
    "        next_q = self.target_q_net(next_state_batch).numpy()\n",
    "        max_next_q = np.amax(next_q, axis=1)\n",
    "        for i in range(state_batch.shape[0]):\n",
    "            target_q_val = reward_batch[i]\n",
    "            target_q_val += 0.95 * max_next_q[i]\n",
    "            target_q[i][action_batch[i]] = target_q_val\n",
    "        training_history = self.q_net.fit(x=state_batch, y=target_q, verbose=0)\n",
    "        loss = training_history.history['loss']\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be56ae6e-2861-4f60-94b7-8017ebe27331",
   "metadata": {},
   "source": [
    "# Deep Q Learning Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c478a5a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Environment:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "class Agent:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "class DeepQLearning:\n",
    "    def __init__(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd4f9b43-2262-4b02-ac88-35c86f746038",
   "metadata": {},
   "source": [
    "# Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3ac00776-530e-449b-8aef-00ac2ddd39f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.5.2 (SDL 2.28.3, Python 3.9.18)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "import pygame\n",
    "from sys import exit\n",
    "from snake_view import *\n",
    "\n",
    "TICK_RATE = 30\n",
    "\n",
    "pygame.init()\n",
    "pygame.display.set_caption(\"Snake\")\n",
    "\n",
    "class Game:\n",
    "    def __init__(self, driver):\n",
    "        self.dqnDriver = driver\n",
    "        self.UI = UI(self.driver.agent.environment.world)\n",
    "        self.clock = pygame.time.Clock()\n",
    "\n",
    "    def game_loop(self):\n",
    "        while True:\n",
    "            self.handle_player_input()\n",
    "            self.dqnDriver.step()\n",
    "                \n",
    "            self.UI.draw_hud()\n",
    "            self.UI.draw_blocks()\n",
    "            pygame.display.update()\n",
    "            self.clock.tick(TICK_RATE)\n",
    "\n",
    "    def handle_player_input(self):\n",
    "        for event in pygame.event.get():\n",
    "            if event.type == pygame.QUIT:\n",
    "                pygame.quit()\n",
    "                exit()\n",
    "\n",
    "            if event.type == pygame.KEYDOWN:\n",
    "                if event.key == pygame.K_RETURN or event.key == pygame.K_SPACE:\n",
    "                    self.gameWorld.__init__()\n",
    "\n",
    "                elif event.key == pygame.K_ESCAPE:\n",
    "                    pygame.quit()\n",
    "                    exit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "04d8b787-b46b-49d1-9558-ced4a4c0662b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# myGame = Game(test)\n",
    "# myGame.game_loop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
